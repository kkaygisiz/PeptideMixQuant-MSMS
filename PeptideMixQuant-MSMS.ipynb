{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4136be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update 03/16/2025: Quantity Peptides with PTMs\n",
    "# This script is powered by pyOpenMS, an open-source Python library for mass spectrometry. \n",
    "\n",
    "# For further documentation, please see https://pyopenms.readthedocs.io\n",
    "# Röst HL, Schmitt U, Aebersold R, Malmström L. pyOpenMS: a Python-based interface to the OpenMS mass-spectrometry algorithm library. Proteomics. 2014 Jan;14(1):74-7. doi: 10.1002/pmic.201300246."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04936dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pyopenms as oms\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from pyopenms import MSExperiment, MzMLFile\n",
    "from pyopenms.plotting import plot_spectrum, mirror_plot_spectrum\n",
    "from tabulate import tabulate\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.patches import PathPatch\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14761a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[+126.11]', '[+126.11]W', '[+126.11]D', '[+126.11]N', '[+126.11]R', '[+126.11]A', '[+126.11]WW', '[+126.11]WD', '[+126.11]WN', '[+126.11]WR', '[+126.11]WA', '[+126.11]DW', '[+126.11]DD', '[+126.11]DN', '[+126.11]DR', '[+126.11]DA', '[+126.11]NW', '[+126.11]ND', '[+126.11]NN', '[+126.11]NR', '[+126.11]NA', '[+126.11]RW', '[+126.11]RD', '[+126.11]RN', '[+126.11]RR', '[+126.11]RA', '[+126.11]AW', '[+126.11]AD', '[+126.11]AN', '[+126.11]AR', '[+126.11]AA', '[+126.11]WWW', '[+126.11]WWD', '[+126.11]WWN', '[+126.11]WWR', '[+126.11]WWA', '[+126.11]WDW', '[+126.11]WDD', '[+126.11]WDN', '[+126.11]WDR', '[+126.11]WDA', '[+126.11]WNW', '[+126.11]WND', '[+126.11]WNN', '[+126.11]WNR', '[+126.11]WNA', '[+126.11]WRW', '[+126.11]WRD', '[+126.11]WRN', '[+126.11]WRR', '[+126.11]WRA', '[+126.11]WAW', '[+126.11]WAD', '[+126.11]WAN', '[+126.11]WAR', '[+126.11]WAA', '[+126.11]DWW', '[+126.11]DWD', '[+126.11]DWN', '[+126.11]DWR', '[+126.11]DWA', '[+126.11]DDW', '[+126.11]DDD', '[+126.11]DDN', '[+126.11]DDR', '[+126.11]DDA', '[+126.11]DNW', '[+126.11]DND', '[+126.11]DNN', '[+126.11]DNR', '[+126.11]DNA', '[+126.11]DRW', '[+126.11]DRD', '[+126.11]DRN', '[+126.11]DRR', '[+126.11]DRA', '[+126.11]DAW', '[+126.11]DAD', '[+126.11]DAN', '[+126.11]DAR', '[+126.11]DAA', '[+126.11]NWW', '[+126.11]NWD', '[+126.11]NWN', '[+126.11]NWR', '[+126.11]NWA', '[+126.11]NDW', '[+126.11]NDD', '[+126.11]NDN', '[+126.11]NDR', '[+126.11]NDA', '[+126.11]NNW', '[+126.11]NND', '[+126.11]NNN', '[+126.11]NNR', '[+126.11]NNA', '[+126.11]NRW', '[+126.11]NRD', '[+126.11]NRN', '[+126.11]NRR', '[+126.11]NRA', '[+126.11]NAW', '[+126.11]NAD', '[+126.11]NAN', '[+126.11]NAR', '[+126.11]NAA', '[+126.11]RWW', '[+126.11]RWD', '[+126.11]RWN', '[+126.11]RWR', '[+126.11]RWA', '[+126.11]RDW', '[+126.11]RDD', '[+126.11]RDN', '[+126.11]RDR', '[+126.11]RDA', '[+126.11]RNW', '[+126.11]RND', '[+126.11]RNN', '[+126.11]RNR', '[+126.11]RNA', '[+126.11]RRW', '[+126.11]RRD', '[+126.11]RRN', '[+126.11]RRR', '[+126.11]RRA', '[+126.11]RAW', '[+126.11]RAD', '[+126.11]RAN', '[+126.11]RAR', '[+126.11]RAA', '[+126.11]AWW', '[+126.11]AWD', '[+126.11]AWN', '[+126.11]AWR', '[+126.11]AWA', '[+126.11]ADW', '[+126.11]ADD', '[+126.11]ADN', '[+126.11]ADR', '[+126.11]ADA', '[+126.11]ANW', '[+126.11]AND', '[+126.11]ANN', '[+126.11]ANR', '[+126.11]ANA', '[+126.11]ARW', '[+126.11]ARD', '[+126.11]ARN', '[+126.11]ARR', '[+126.11]ARA', '[+126.11]AAW', '[+126.11]AAD', '[+126.11]AAN', '[+126.11]AAR', '[+126.11]AAA', 'WR', 'WN', 'WA', 'WD', 'WRWR', 'WRWN', 'WRWA', 'WRWD', 'WNWR', 'WNWN', 'WNWA', 'WNWD', 'WAWR', 'WAWN', 'WAWA', 'WAWD', 'WDWR', 'WDWN', 'WDWA', 'WDWD']\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Function to create a custom amino acid sequence with modification\n",
    "def create_custom_aa_sequence(sequence):\n",
    "    # Use the AASequence class to parse the peptide sequence\n",
    "    aa_seq = oms.AASequence.fromString(sequence)\n",
    "    return aa_seq\n",
    "\n",
    "# Define a function to generate peptide combinations\n",
    "def generate_combinations(peptides, min_length, max_length):\n",
    "    all_combinations = []\n",
    "    \n",
    "    # Generate sequences with cutsom PTM, e.g. \"[+126.11]\" at the first position\n",
    "    for length in range(min_length, max_length + 1):\n",
    "        if length == 1:\n",
    "            all_combinations.append(\"[+126.11]\")  # Only this when length is 1\n",
    "        else:\n",
    "            for seq in product(peptides, repeat=length-1):\n",
    "                all_combinations.append(\"[+126.11]\" + ''.join(seq))\n",
    "\n",
    "    # Generate sequences using only [\"WR\", \"WN\", \"WA\", \"WD\"], with lengths 2, 4, 6...\n",
    "    building_blocks = [\"WR\", \"WN\", \"WA\", \"WD\"]\n",
    "    for length in range(2, max_length + 1, 2):  # Only even lengths: 2, 4, 6, ...\n",
    "        for seq in product(building_blocks, repeat=length // 2):  # Each unit is 2 letters\n",
    "            all_combinations.append(''.join(seq))\n",
    "    \n",
    "    return all_combinations\n",
    "\n",
    "# Peptides for the sequences starting with \"[+127.11]\"\n",
    "peptides = [\"W\", \"D\", \"N\", \"R\", \"A\"]  \n",
    "min_length = 1\n",
    "max_length = 4  # Adjusted to allow up to length 6\n",
    "\n",
    "List_Of_Peptides = generate_combinations(peptides, min_length, max_length)\n",
    "\n",
    "# Print results\n",
    "print(List_Of_Peptides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5e0af524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "[+126.11] [+126.11]\n",
      "[+126.11]W [+126.11]W\n",
      "[+126.11]D [+126.11]D\n",
      "[+126.11]N [+126.11]N\n",
      "[+126.11]R [+126.11]R\n",
      "[+126.11]A [+126.11]A\n",
      "[+126.11]WW [+126.11]WW\n",
      "[+126.11]WD [+126.11]WD\n",
      "[+126.11]WN [+126.11]WN\n",
      "[+126.11]WR [+126.11]WR\n",
      "[+126.11]WA [+126.11]WA\n",
      "[+126.11]DW [+126.11]DW\n",
      "[+126.11]DD [+126.11]DD\n",
      "[+126.11]DN [+126.11]DN\n",
      "[+126.11]DR [+126.11]DR\n",
      "[+126.11]DA [+126.11]DA\n",
      "[+126.11]NW [+126.11]NW\n",
      "[+126.11]ND [+126.11]ND\n",
      "[+126.11]NN [+126.11]NN\n",
      "[+126.11]NR [+126.11]NR\n",
      "[+126.11]NA [+126.11]NA\n",
      "[+126.11]RW [+126.11]RW\n",
      "[+126.11]RD [+126.11]RD\n",
      "[+126.11]RN [+126.11]RN\n",
      "[+126.11]RR [+126.11]RR\n",
      "[+126.11]RA [+126.11]RA\n",
      "[+126.11]AW [+126.11]AW\n",
      "[+126.11]AD [+126.11]AD\n",
      "[+126.11]AN [+126.11]AN\n",
      "[+126.11]AR [+126.11]AR\n",
      "[+126.11]AA [+126.11]AA\n",
      "[+126.11]WWW [+126.11]WWW\n",
      "[+126.11]WWD [+126.11]WWD\n",
      "[+126.11]WWN [+126.11]WWN\n",
      "[+126.11]WWR [+126.11]WWR\n",
      "[+126.11]WWA [+126.11]WWA\n",
      "[+126.11]WDW [+126.11]WDW\n",
      "[+126.11]WDD [+126.11]WDD\n",
      "[+126.11]WDN [+126.11]WDN\n",
      "[+126.11]WDR [+126.11]WDR\n",
      "[+126.11]WDA [+126.11]WDA\n",
      "[+126.11]WNW [+126.11]WNW\n",
      "[+126.11]WND [+126.11]WND\n",
      "[+126.11]WNN [+126.11]WNN\n",
      "[+126.11]WNR [+126.11]WNR\n",
      "[+126.11]WNA [+126.11]WNA\n",
      "[+126.11]WRW [+126.11]WRW\n",
      "[+126.11]WRD [+126.11]WRD\n",
      "[+126.11]WRN [+126.11]WRN\n",
      "[+126.11]WRR [+126.11]WRR\n",
      "[+126.11]WRA [+126.11]WRA\n",
      "[+126.11]WAW [+126.11]WAW\n",
      "[+126.11]WAD [+126.11]WAD\n",
      "[+126.11]WAN [+126.11]WAN\n",
      "[+126.11]WAR [+126.11]WAR\n",
      "[+126.11]WAA [+126.11]WAA\n",
      "[+126.11]DWW [+126.11]DWW\n",
      "[+126.11]DWD [+126.11]DWD\n",
      "[+126.11]DWN [+126.11]DWN\n",
      "[+126.11]DWR [+126.11]DWR\n",
      "[+126.11]DWA [+126.11]DWA\n",
      "[+126.11]DDW [+126.11]DDW\n",
      "[+126.11]DDD [+126.11]DDD\n",
      "[+126.11]DDN [+126.11]DDN\n",
      "[+126.11]DDR [+126.11]DDR\n",
      "[+126.11]DDA [+126.11]DDA\n",
      "[+126.11]DNW [+126.11]DNW\n",
      "[+126.11]DND [+126.11]DND\n",
      "[+126.11]DNN [+126.11]DNN\n",
      "[+126.11]DNR [+126.11]DNR\n",
      "[+126.11]DNA [+126.11]DNA\n",
      "[+126.11]DRW [+126.11]DRW\n",
      "[+126.11]DRD [+126.11]DRD\n",
      "[+126.11]DRN [+126.11]DRN\n",
      "[+126.11]DRR [+126.11]DRR\n",
      "[+126.11]DRA [+126.11]DRA\n",
      "[+126.11]DAW [+126.11]DAW\n",
      "[+126.11]DAD [+126.11]DAD\n",
      "[+126.11]DAN [+126.11]DAN\n",
      "[+126.11]DAR [+126.11]DAR\n",
      "[+126.11]DAA [+126.11]DAA\n",
      "[+126.11]NWW [+126.11]NWW\n",
      "[+126.11]NWD [+126.11]NWD\n",
      "[+126.11]NWN [+126.11]NWN\n",
      "[+126.11]NWR [+126.11]NWR\n",
      "[+126.11]NWA [+126.11]NWA\n",
      "[+126.11]NDW [+126.11]NDW\n",
      "[+126.11]NDD [+126.11]NDD\n",
      "[+126.11]NDN [+126.11]NDN\n",
      "[+126.11]NDR [+126.11]NDR\n",
      "[+126.11]NDA [+126.11]NDA\n",
      "[+126.11]NNW [+126.11]NNW\n",
      "[+126.11]NND [+126.11]NND\n",
      "[+126.11]NNN [+126.11]NNN\n",
      "[+126.11]NNR [+126.11]NNR\n",
      "[+126.11]NNA [+126.11]NNA\n",
      "[+126.11]NRW [+126.11]NRW\n",
      "[+126.11]NRD [+126.11]NRD\n",
      "[+126.11]NRN [+126.11]NRN\n",
      "[+126.11]NRR [+126.11]NRR\n",
      "[+126.11]NRA [+126.11]NRA\n",
      "[+126.11]NAW [+126.11]NAW\n",
      "[+126.11]NAD [+126.11]NAD\n",
      "[+126.11]NAN [+126.11]NAN\n",
      "[+126.11]NAR [+126.11]NAR\n",
      "[+126.11]NAA [+126.11]NAA\n",
      "[+126.11]RWW [+126.11]RWW\n",
      "[+126.11]RWD [+126.11]RWD\n",
      "[+126.11]RWN [+126.11]RWN\n",
      "[+126.11]RWR [+126.11]RWR\n",
      "[+126.11]RWA [+126.11]RWA\n",
      "[+126.11]RDW [+126.11]RDW\n",
      "[+126.11]RDD [+126.11]RDD\n",
      "[+126.11]RDN [+126.11]RDN\n",
      "[+126.11]RDR [+126.11]RDR\n",
      "[+126.11]RDA [+126.11]RDA\n",
      "[+126.11]RNW [+126.11]RNW\n",
      "[+126.11]RND [+126.11]RND\n",
      "[+126.11]RNN [+126.11]RNN\n",
      "[+126.11]RNR [+126.11]RNR\n",
      "[+126.11]RNA [+126.11]RNA\n",
      "[+126.11]RRW [+126.11]RRW\n",
      "[+126.11]RRD [+126.11]RRD\n",
      "[+126.11]RRN [+126.11]RRN\n",
      "[+126.11]RRR [+126.11]RRR\n",
      "[+126.11]RRA [+126.11]RRA\n",
      "[+126.11]RAW [+126.11]RAW\n",
      "[+126.11]RAD [+126.11]RAD\n",
      "[+126.11]RAN [+126.11]RAN\n",
      "[+126.11]RAR [+126.11]RAR\n",
      "[+126.11]RAA [+126.11]RAA\n",
      "[+126.11]AWW [+126.11]AWW\n",
      "[+126.11]AWD [+126.11]AWD\n",
      "[+126.11]AWN [+126.11]AWN\n",
      "[+126.11]AWR [+126.11]AWR\n",
      "[+126.11]AWA [+126.11]AWA\n",
      "[+126.11]ADW [+126.11]ADW\n",
      "[+126.11]ADD [+126.11]ADD\n",
      "[+126.11]ADN [+126.11]ADN\n",
      "[+126.11]ADR [+126.11]ADR\n",
      "[+126.11]ADA [+126.11]ADA\n",
      "[+126.11]ANW [+126.11]ANW\n",
      "[+126.11]AND [+126.11]AND\n",
      "[+126.11]ANN [+126.11]ANN\n",
      "[+126.11]ANR [+126.11]ANR\n",
      "[+126.11]ANA [+126.11]ANA\n",
      "[+126.11]ARW [+126.11]ARW\n",
      "[+126.11]ARD [+126.11]ARD\n",
      "[+126.11]ARN [+126.11]ARN\n",
      "[+126.11]ARR [+126.11]ARR\n",
      "[+126.11]ARA [+126.11]ARA\n",
      "[+126.11]AAW [+126.11]AAW\n",
      "[+126.11]AAD [+126.11]AAD\n",
      "[+126.11]AAN [+126.11]AAN\n",
      "[+126.11]AAR [+126.11]AAR\n",
      "[+126.11]AAA [+126.11]AAA\n",
      "WR WR\n",
      "WN WN\n",
      "WA WA\n",
      "WD WD\n",
      "WRWR WRWR\n",
      "WRWN WRWN\n",
      "WRWA WRWA\n",
      "WRWD WRWD\n",
      "WNWR WNWR\n",
      "WNWN WNWN\n",
      "WNWA WNWA\n",
      "WNWD WNWD\n",
      "WAWR WAWR\n",
      "WAWN WAWN\n",
      "WAWA WAWA\n",
      "WAWD WAWD\n",
      "WDWR WDWR\n",
      "WDWN WDWN\n",
      "WDWA WDWA\n",
      "WDWD WDWD\n"
     ]
    }
   ],
   "source": [
    "# Set intensity threshold and create FASTA file using the List of Peptides\n",
    "\n",
    "MW_toleranz = 0.01\n",
    "Int_threshold = 10000.0\n",
    "\n",
    "entries = []\n",
    "\n",
    "for i in range(len(List_Of_Peptides)):    \n",
    "    tmp = oms.FASTAEntry()  # one entry in a FASTA file\n",
    "    tmp.sequence = List_Of_Peptides[i]\n",
    "    tmp.description = List_Of_Peptides[i]\n",
    "    tmp.identifier = List_Of_Peptides[i]\n",
    "    entries.append(tmp)\n",
    "\n",
    "f = oms.FASTAFile()\n",
    "f.store(\"peptides.fasta\", entries)\n",
    "\n",
    "print(len(entries))\n",
    "for e in entries:\n",
    "    print(e.identifier, e.sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7989fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working directory\n",
    "# Get the current directory where the script is located\n",
    "current_directory = r'C:\\pathway\\to\\directory' #change to your directory\n",
    "\n",
    "# Specify the file or directory relative to the current directory where the mz.XML files to be analzed are located\n",
    "relative_path = r'data'\n",
    "\n",
    "# Combine the current directory with the relative path\n",
    "directory = os.path.join(current_directory, relative_path)\n",
    "print(directory)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each mzXML file\n",
    "def process_file(file_path):\n",
    "    exp= MSExperiment()\n",
    "    oms.MzXMLFile().load(file_path, exp)\n",
    "    spectra = exp.getSpectra()\n",
    "    out_file_name = f\"{os.path.splitext(filename)[0]}_output.csv\"\n",
    "    # Check if the file already exists to decide whether to write the header\n",
    "    file_exists = os.path.isfile(out_file_name)\n",
    "\n",
    "    spa = oms.SpectrumAlignment()\n",
    "    p = spa.getParameters()\n",
    "\n",
    "    # For low resolution MS data, set tolerance for MS1 calculated and experimental match\n",
    "    # typically use 0.5 Da tolerance for low resolution data\n",
    "    #p.setValue(\"tolerance\", 0.5)\n",
    "    #p.setValue(\"is_relative_tolerance\", \"false\")\n",
    "\n",
    "    # For high resolution MS data, set tolerance for MS1 calculated and experimental match\n",
    "    # typically use tolerance between 8 ppm and 20 ppm for high-resolution data\n",
    "    p.setValue(\"tolerance\", 10.0) \n",
    "    p.setValue(\"is_relative_tolerance\", \"true\")\n",
    "    spa.setParameters(p)\n",
    "\n",
    "    spa_iso = oms.SpectrumAlignment()\n",
    "    p_iso = spa_iso.getParameters()\n",
    "\n",
    "    # For low resolution MS data, set tolerance for isotope pattern match\n",
    "    # typically use 0.5 Da tolerance for low resolution data\n",
    "    #p.setValue(\"tolerance\", 0.5)\n",
    "    #p.setValue(\"is_relative_tolerance\", \"false\")\n",
    "\n",
    "    # For high resolution MS data, set tolerance for isotope pattern match\n",
    "    # typically use tolreance between 8 ppm and 20 ppm for high-resolution data\n",
    "    p_iso.setValue(\"tolerance\", 10.0) # typically use tolerance between 8 ppm and 20 ppm for high-resolution data\n",
    "    p_iso.setValue(\"is_relative_tolerance\", \"true\")\n",
    "    spa_iso.setParameters(p_iso)\n",
    "\n",
    "    tsg = oms.TheoreticalSpectrumGenerator()\n",
    "\n",
    "    p2 = oms.Param()\n",
    "    p2.setValue(\"add_a_ions\", \"true\")\n",
    "        # adding n-term ion (in this case, a1 and b1)\n",
    "    p2.setValue(\"add_first_prefix_ion\", \"true\")\n",
    "    p2.setValue(\"add_precursor_peaks\", \"true\")\n",
    "        # standard is to add precursor peaks with only the largest charge\n",
    "    p2.setValue(\"add_all_precursor_charges\", \"false\")\n",
    "    p2.setValue(\"add_losses\", \"false\")\n",
    "    p2.setValue(\"add_metainfo\", \"false\")\n",
    "    tsg.setParameters(p2)\n",
    "\n",
    "\n",
    "\n",
    "    entries = []\n",
    "\n",
    "    f = oms.FASTAFile()\n",
    "    f.load(\"peptides.fasta\", entries)\n",
    "    print(len(entries))\n",
    "\n",
    "    # Assuming you have time and intensity data\n",
    "    time = [spectrum.getRT() for spectrum in exp]\n",
    "    time_ms1 = []\n",
    "    print(f'time: {time}')\n",
    "    \n",
    "    mass_intensities = [[] for i in range(len(entries))]\n",
    "\n",
    "    area = [0 for i in range(len(entries))]\n",
    "\n",
    "    filtered_spectra = [[] for i in range(len(entries))]\n",
    "    all_spectra = []\n",
    "\n",
    "    for e in range(len(entries)):\n",
    "        seq = oms.AASequence.fromString(entries[e].sequence)\n",
    "        # some mass calculations\n",
    "        mfull = seq.getMonoWeight()  # weight of M\n",
    "        mz2 = seq.getMZ(2)  # same as above\n",
    "        mz1 = seq.getMZ(1)  # same as above\n",
    "        print(\"Monoisotopic mass of peptide\", entries[e].identifier, \" is\", mfull)\n",
    "        print(\"Monoisotopic m/z of\" , entries[e].identifier, \"[M+H]+ is\", mz1)\n",
    "        print(\"Monoisotopic m/z of\" , entries[e].identifier, \"[M+2H]2+ is\", mz2)\n",
    "      \n",
    "        # print coarse structure of isotope distribution\n",
    "        generator = oms.CoarseIsotopePatternGenerator(5) # adjust number for number of calculated isotope pattern\n",
    "        isotope_distribution = seq.getFormula().getIsotopeDistribution(generator)\n",
    "    \n",
    "        iso_spec = oms.MSSpectrum()\n",
    "        for iso in isotope_distribution.getContainer():\n",
    "            peak = oms.Peak1D()\n",
    "            peak.setMZ(iso.getMZ())\n",
    "            peak.setIntensity(iso.getIntensity())\n",
    "            iso_spec.push_back(peak)\n",
    "        \n",
    "        theo_spec = oms.MSSpectrum()\n",
    "        peptide = oms.AASequence.fromString(entries[e].sequence)\n",
    "            # standard behavior is adding b- and y-ions\n",
    "        tsg.getSpectrum(theo_spec, peptide, 1, 1)\n",
    "\n",
    "         # Iterate over annotated ions and their masses\n",
    "        print(\"Spectrum fragment of\", peptide, \"has\", theo_spec.size(), \"peaks.\")\n",
    "\n",
    "        \n",
    "        #prints fragment pattern\n",
    "        mz_values, intensities = theo_spec.get_peaks()\n",
    "\n",
    "        print(f\"\\nMS2 Fragments for Peptide: {peptide}\")\n",
    "        print(f\"{'m/z':<10} {'Intensity':<10}\")\n",
    "        print(\"-\" * 25)\n",
    "\n",
    "        for mz, intensity in zip(mz_values, intensities):\n",
    "            print(f\"{mz:.4f}    {intensity:.2f}\")\n",
    "        \n",
    "\n",
    "        #filters spectra according to set thresholds for MS1, fragment and isotope patterns\n",
    "        \n",
    "        for spectrum in exp:\n",
    "            alignment = []\n",
    "            # align both spectra\n",
    "            spa.getSpectrumAlignment(alignment, theo_spec, spectrum)\n",
    "\n",
    "            alignment_iso = []\n",
    "            # align both spectra\n",
    "            spa_iso.getSpectrumAlignment(alignment_iso, iso_spec, spectrum)\n",
    "\n",
    "            mz, intensity = spectrum.get_peaks()\n",
    "            target_masses = [mz1, mz2]\n",
    "            filtered_peaks = []       \n",
    "            if (spectrum.getMSLevel() == 1):\n",
    "                if ((len(alignment) >= 2) & (len(alignment_iso) >= 2)) | (len(entries[e].sequence) <= 1):     # increase values if higher accuracy is desired\n",
    "                    for m, i in zip(mz, intensity):\n",
    "                        for mass in target_masses:\n",
    "                            if (m >= mass - MW_toleranz) & (m <= mass + MW_toleranz):\n",
    "                                filtered_peaks.append((m,i))                        \n",
    "                filtered_spectra[e].append(filtered_peaks)\n",
    "\n",
    "            \n",
    "            if e == 0:\n",
    "                #Calculation of total chromatogram\n",
    "                if spectrum.getMSLevel() == 1:\n",
    "                    all_peaks = [(m, i) for m, i in zip(mz, intensity)]\n",
    "                    all_spectra.append(all_peaks)\n",
    "                    time_ms1.append(spectrum.getRT())\n",
    "\n",
    "        # Open a CSV file for writing, output is saved in current_directory\n",
    "        with open(out_file_name, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            # Write the header\n",
    "            if not file_exists:\n",
    "                writer.writerow(['peptide', 'mass', 'area'])\n",
    "                file_exists = True\n",
    "\n",
    "            mass_intensity = [sum(intensity for mz, intensity in peaks) for peaks in filtered_spectra[e]]\n",
    "            mass_intensities[e] = mass_intensity\n",
    "            area[e]=sum(mass_intensities[e])\n",
    "            print(f\"peptide = {entries[e].identifier}, mass = {mz1}, area = {area[e]}\")\n",
    "            writer.writerow([entries[e].identifier, mz1, area[e]])\n",
    "\n",
    "\n",
    "    sum_all_intensity = [sum(intensity for mz, intensity in peaks) for peaks in all_spectra]\n",
    "    \n",
    "    plt.figure().set_figwidth(25)\n",
    "    for i in range(len(entries)):\n",
    "        mass_intensity = [sum(intensity for mz, intensity in peaks) for peaks in filtered_spectra[i]]\n",
    "        mass_intensities[i] = mass_intensity\n",
    "        area[i]=sum(mass_intensities[i])\n",
    "        current_mass_intensity = area[i]\n",
    "        current_mass_intensity = int(current_mass_intensity)\n",
    "        # Plot the chromatogram\n",
    "        if current_mass_intensity >= Int_threshold:\n",
    "            plt.fill(time_ms1, mass_intensities[i], label=entries[i].identifier)\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.xlabel('Time')\n",
    "            plt.ylabel('Intensity')\n",
    "            plt.title('Integrated Chromatogram')\n",
    "\n",
    "    print(sum_all_intensity)\n",
    "    plt.plot(time_ms1, sum_all_intensity)\n",
    "    plt.savefig(f\"{os.path.splitext(filename)[0]}_plot.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9833942",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.mzXML'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        if os.path.exists(file_path):\n",
    "            process_file(file_path)\n",
    "\n",
    "            # Create the output file name\n",
    "            output_file_name = f\"{os.path.splitext(filename)[0]}_output.csv\"\n",
    "            \n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LCMS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
